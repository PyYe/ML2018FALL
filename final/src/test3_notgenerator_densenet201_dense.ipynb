{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy.optimize as opt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.image import resize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, LeakyReLU, PReLU, Input\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, TensorBoard, ReduceLROnPlateau\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.densenet import DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "# Setting the seed for numpy-generated random numbers\n",
    "np.random.seed(37)\n",
    "# Setting the seed for python random numbers\n",
    "rn.seed(1254)\n",
    "# Setting the graph-level random seed.\n",
    "tf.set_random_seed(89)\n",
    "# 自動增長 GPU 記憶體用量\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "# 設定 Keras 使用的 Session\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test3_notgenerator_densenet201_dense\"# os.path.basename(__file__).split('.')[0]\n",
    "PATH = os.getcwd()\n",
    "TRAIN = os.path.join(os.getcwd(), 'data', 'train')\n",
    "TEST = os.path.join(os.getcwd(), 'data', 'test')\n",
    "PREPROCESSED = os.path.join(os.getcwd(), 'preprocessed_data')\n",
    "LABELS = os.path.join(os.getcwd(), 'data', 'train.csv')\n",
    "SAMPLE = os.path.join(os.getcwd(), 'data', 'sample_submission.csv')\n",
    "MODEL = os.path.join(os.getcwd(), 'model', NAME+'.h5')\n",
    "RESULT = os.path.join(os.getcwd(), 'result', NAME+'_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_LENGTH = 512\n",
    "IMAGE_WIDTH = 512\n",
    "CHANNEL_NUM = 4\n",
    "TRAIN_SIZE = int(len(os.listdir(TRAIN))/4)\n",
    "LABEL_NUM = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(os.path.join(PREPROCESSED, 'train_RGBY_original_x.npy'))\n",
    "train_y = np.load(os.path.join(PREPROCESSED, 'train_RGBY_original_y.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use ImageDataGenerator to implement data augmentation. \n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range = 40,\n",
    "            width_shift_range = 0.3,\n",
    "            height_shift_range = 0.3,\n",
    "            zoom_range = [0.6, 1.4],\n",
    "            shear_range = 0.4,\n",
    "            horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    \n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Dense(CHANNEL_NUM)(bn)\n",
    "    x = Dense(3)(x)\n",
    "    #conv2d = Conv2D(3, kernel_size = (1, 1), strides=(1,1), padding = 'same', kernel_initializer = 'glorot_normal')(bn)\n",
    "    \n",
    "    #x = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(IMAGE_LENGTH, IMAGE_WIDTH, 3), pooling='avg')(conv2d)\n",
    "    x = DenseNet201(include_top=False, weights='imagenet', input_shape=(IMAGE_LENGTH, IMAGE_WIDTH, 3), pooling='avg')(x)\n",
    "    \n",
    "    #x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = Dense(512, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='softmax')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    input_shape=(IMAGE_LENGTH,IMAGE_WIDTH,CHANNEL_NUM), \n",
    "    n_out=LABEL_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512, 512, 4)       16        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512, 512, 4)       20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512, 512, 3)       15        \n",
      "_________________________________________________________________\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                53788     \n",
      "=================================================================\n",
      "Total params: 18,375,823\n",
      "Trainable params: 53,831\n",
      "Non-trainable params: 18,321,992\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "model.layers[-2].trainable = False\n",
    "### Show model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4)\n",
    "epochs_to_wait_for_improve = 10\n",
    "batch_size = 4\n",
    "#valid_split_ratio = 0.2\n",
    "n_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = np.load(os.path.join(PREPROCESSED, 'class_weight.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=focal_loss(), optimizer=adam, metrics=[f1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping_callback = EarlyStopping(monitor='val_f1', patience=epochs_to_wait_for_improve)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(MODEL, monitor='val_f1'\n",
    "                                          , verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OneDay\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\keras\\callbacks.py:928: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` insted.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27964 samples, validate on 3108 samples\n",
      "Epoch 1/4\n",
      "27964/27964 [==============================] - 1811s 65ms/step - loss: 3.2680 - f1: 5.0609e-04 - val_loss: 3.8627 - val_f1: 0.0011\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.00106, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 2/4\n",
      "27964/27964 [==============================] - 1782s 64ms/step - loss: 2.9596 - f1: 0.0021 - val_loss: 3.8476 - val_f1: 0.0026\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.00106 to 0.00259, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 3/4\n",
      "27964/27964 [==============================] - 1777s 64ms/step - loss: 2.8391 - f1: 0.0036 - val_loss: 4.0105 - val_f1: 0.0052\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.00259 to 0.00524, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 4/4\n",
      "27964/27964 [==============================] - 1781s 64ms/step - loss: 2.7708 - f1: 0.0049 - val_loss: 4.2517 - val_f1: 0.0069\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.00524 to 0.00690, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_history=model.fit(train_x, train_y\n",
    "                                      , batch_size = batch_size\n",
    "                                      #, steps_per_epoch = len(train_x)*10 / batch_size\n",
    "                                      , epochs = n_epochs\n",
    "                                      , validation_split = 0.1\n",
    "                                    , shuffle=True, class_weight=cw\n",
    "                                      , callbacks=[\n",
    "                                          #early_stopping_callback, \n",
    "                                          checkpoint_callback, TensorBoard(log_dir='./tmp/log')\n",
    "                                                   , ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001)\n",
    "                                                  ]\n",
    "                                      , verbose=1)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=./tmp/log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512, 512, 4)       16        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512, 512, 4)       20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512, 512, 3)       15        \n",
      "_________________________________________________________________\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                53788     \n",
      "=================================================================\n",
      "Total params: 282,895\n",
      "Trainable params: 53,831\n",
      "Non-trainable params: 229,064\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OneDay\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\keras\\engine\\training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "### Show model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=focal_loss(), optimizer=adam, metrics=[f1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27964 samples, validate on 3108 samples\n",
      "Epoch 1/20\n",
      "27964/27964 [==============================] - 2603s 93ms/step - loss: 2.4172 - f1: 0.0183 - val_loss: 2.7452 - val_f1: 0.0455\n",
      "\n",
      "Epoch 00001: val_f1 improved from 0.00690 to 0.04554, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 2/20\n",
      "27964/27964 [==============================] - 2587s 93ms/step - loss: 1.9666 - f1: 0.0310 - val_loss: 2.2689 - val_f1: 0.0615\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.04554 to 0.06145, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 3/20\n",
      "27964/27964 [==============================] - 2556s 91ms/step - loss: 1.7020 - f1: 0.0413 - val_loss: 2.6839 - val_f1: 0.0642\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.06145 to 0.06419, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 4/20\n",
      "27964/27964 [==============================] - 2547s 91ms/step - loss: 1.4975 - f1: 0.0514 - val_loss: 2.3574 - val_f1: 0.0688\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.06419 to 0.06879, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 5/20\n",
      "27964/27964 [==============================] - 2568s 92ms/step - loss: 1.1738 - f1: 0.0671 - val_loss: inf - val_f1: 0.0767\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.06879 to 0.07674, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 6/20\n",
      "27964/27964 [==============================] - 2533s 91ms/step - loss: 1.0383 - f1: 0.0758 - val_loss: 1.8795 - val_f1: 0.0800\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.07674 to 0.08001, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 7/20\n",
      "27964/27964 [==============================] - 2524s 90ms/step - loss: 0.9626 - f1: 0.0801 - val_loss: 1.7772 - val_f1: 0.0835\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.08001 to 0.08354, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 8/20\n",
      "27964/27964 [==============================] - 2524s 90ms/step - loss: 0.9000 - f1: 0.0833 - val_loss: 1.8726 - val_f1: 0.0797\n",
      "\n",
      "Epoch 00008: val_f1 did not improve from 0.08354\n",
      "Epoch 9/20\n",
      "27964/27964 [==============================] - 2526s 90ms/step - loss: 0.8596 - f1: 0.0854 - val_loss: 1.8796 - val_f1: 0.0843\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.08354 to 0.08428, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 10/20\n",
      "27964/27964 [==============================] - 2528s 90ms/step - loss: 0.7551 - f1: 0.0902 - val_loss: 1.7753 - val_f1: 0.0870\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.08428 to 0.08705, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 11/20\n",
      "27964/27964 [==============================] - 2524s 90ms/step - loss: 0.7024 - f1: 0.0925 - val_loss: 1.8696 - val_f1: 0.0843\n",
      "\n",
      "Epoch 00011: val_f1 did not improve from 0.08705\n",
      "Epoch 12/20\n",
      "27964/27964 [==============================] - 2523s 90ms/step - loss: 0.6784 - f1: 0.0930 - val_loss: inf - val_f1: 0.0854\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.08705\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 13/20\n",
      "27964/27964 [==============================] - 2518s 90ms/step - loss: 0.6428 - f1: 0.0943 - val_loss: 1.7380 - val_f1: 0.0873\n",
      "\n",
      "Epoch 00013: val_f1 improved from 0.08705 to 0.08725, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 14/20\n",
      "27964/27964 [==============================] - 2522s 90ms/step - loss: 0.6178 - f1: 0.0941 - val_loss: 1.7309 - val_f1: 0.0868\n",
      "\n",
      "Epoch 00014: val_f1 did not improve from 0.08725\n",
      "Epoch 15/20\n",
      "27964/27964 [==============================] - 2524s 90ms/step - loss: 0.6034 - f1: 0.0951 - val_loss: 1.7494 - val_f1: 0.0891\n",
      "\n",
      "Epoch 00015: val_f1 improved from 0.08725 to 0.08913, saving model to C:\\Users\\OneDay\\Downloads\\ML2018FALL\\final\\Human_Protein_Atlas_Image_classification\\model\\test3_notgenerator_densenet201_dense.h5\n",
      "Epoch 16/20\n",
      "27964/27964 [==============================] - 2523s 90ms/step - loss: 0.5960 - f1: 0.0950 - val_loss: 1.6549 - val_f1: 0.0878\n",
      "\n",
      "Epoch 00016: val_f1 did not improve from 0.08913\n",
      "Epoch 17/20\n",
      "27964/27964 [==============================] - 2552s 91ms/step - loss: 0.5864 - f1: 0.0949 - val_loss: 1.6368 - val_f1: 0.0869\n",
      "\n",
      "Epoch 00017: val_f1 did not improve from 0.08913\n",
      "Epoch 18/20\n",
      "27964/27964 [==============================] - 2577s 92ms/step - loss: 0.5788 - f1: 0.0960 - val_loss: 1.6399 - val_f1: 0.0879\n",
      "\n",
      "Epoch 00018: val_f1 did not improve from 0.08913\n",
      "Epoch 19/20\n",
      "27964/27964 [==============================] - 2571s 92ms/step - loss: 0.5761 - f1: 0.0952 - val_loss: 1.6926 - val_f1: 0.0854\n",
      "\n",
      "Epoch 00019: val_f1 did not improve from 0.08913\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 20/20\n",
      "27964/27964 [==============================] - 2580s 92ms/step - loss: 0.5591 - f1: 0.0949 - val_loss: 1.6358 - val_f1: 0.0865\n",
      "\n",
      "Epoch 00020: val_f1 did not improve from 0.08913\n"
     ]
    }
   ],
   "source": [
    "train_history=model.fit(train_x, train_y\n",
    "                                      , batch_size = batch_size\n",
    "                                      #, steps_per_epoch = len(train_x)*10 / batch_size\n",
    "                                      , epochs = n_epochs\n",
    "                                      , validation_split = 0.1\n",
    "                                    , shuffle=True, class_weight=cw\n",
    "                                      , callbacks=[\n",
    "                                          #early_stopping_callback, \n",
    "                                          checkpoint_callback, TensorBoard(log_dir='./tmp/log')\n",
    "                                                   , ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.00001)\n",
    "                                                  ]\n",
    "                                      , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27964 samples, validate on 3108 samples\n",
      "Epoch 1/20\n",
      "27964/27964 [==============================] - 2573s 92ms/step - loss: 0.5390 - f1: 0.0959 - val_loss: 1.6511 - val_f1: 0.0871\n",
      "\n",
      "Epoch 00001: val_f1 did not improve from 0.08913\n",
      "Epoch 2/20\n",
      "27964/27964 [==============================] - 2601s 93ms/step - loss: 0.5402 - f1: 0.0958 - val_loss: 1.6287 - val_f1: 0.0867\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.08913\n",
      "Epoch 3/20\n",
      "27964/27964 [==============================] - 2625s 94ms/step - loss: 0.5376 - f1: 0.0950 - val_loss: 1.6006 - val_f1: 0.0871\n",
      "\n",
      "Epoch 00003: val_f1 did not improve from 0.08913\n",
      "Epoch 4/20\n",
      "27964/27964 [==============================] - 2610s 93ms/step - loss: 0.5298 - f1: 0.0960 - val_loss: 1.6356 - val_f1: 0.0863\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.08913\n",
      "Epoch 5/20\n",
      "27964/27964 [==============================] - 2591s 93ms/step - loss: 0.5235 - f1: 0.0960 - val_loss: 1.6704 - val_f1: 0.0880\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.08913\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 6/20\n",
      "27964/27964 [==============================] - 2623s 94ms/step - loss: 0.5199 - f1: 0.0955 - val_loss: 1.6130 - val_f1: 0.0874\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.08913\n",
      "Epoch 7/20\n",
      "27964/27964 [==============================] - 2634s 94ms/step - loss: 0.5161 - f1: 0.0954 - val_loss: 1.6485 - val_f1: 0.0871\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.08913\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 8/20\n",
      "  960/27964 [>.............................] - ETA: 39:21 - loss: 0.4996 - f1: 0.0965"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9a118bfd6887>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                    \u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                   ]\n\u001b[1;32m---> 12\u001b[1;33m                                       , verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML2018FALL_NEW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history=model.fit(train_x, train_y\n",
    "                                      , batch_size = batch_size\n",
    "                                      #, steps_per_epoch = len(train_x)*10 / batch_size\n",
    "                                      , epochs = n_epochs\n",
    "                                      , validation_split = 0.1\n",
    "                                    , shuffle=True, class_weight=cw\n",
    "                                      , callbacks=[\n",
    "                                          #early_stopping_callback, \n",
    "                                          checkpoint_callback, TensorBoard(log_dir='./tmp/log')\n",
    "                                                   , ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.00001)\n",
    "                                                  ]\n",
    "                                      , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML2018FALL_NEW]",
   "language": "python",
   "name": "conda-env-ML2018FALL_NEW-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
